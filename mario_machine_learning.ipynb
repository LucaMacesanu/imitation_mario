{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3319745f-b1c0-4218-9269-52e79f8461dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group Number: 27\n",
    "#Group Members: Luca Macesanu, Samik Singh, Carson Ngyuen, Mathew Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61887bd6-01fc-4527-a964-ef48e9a1a6c6",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "For our project, we wanted to create a model to play a videogame. During the process, we first considered playing pokemon. However, we were unable to find a robust dataset to use. Therefore, we ended up moving forward with the gym retro library where we were able to load games and create our own dataset. The game we wanted to choose was Mortal Kombat. However, that didn't work as we were unable to get it to run. Therefore, we settled on Super Mario Bros. Therefore, we decided to create models that would be able to complete world 1-1 of Super Mario Bros.\n",
    "\n",
    "\n",
    "We first collected data. Then we moved on to using classification based approaches similar to what we learned in class. Lastly, we used Proximal Policy Optimization to expand upon our knowledge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99993be6-415c-4842-8c57-e7a5494846b8",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "\n",
    "Since there were no existing datasets for our project, we decided to collect our own data. We collected a total of 128942 state action pairs in order to treat gameplay as a classification problem in order to predict how a human would play the game. \n",
    "\n",
    "\n",
    "Since we collected the data, data cleaning was more minimal. We remapped our action spaces as there were many action outputs that matched the state of the game. By consolidating these actions, we reduced the overall spread of our data. We also scaled the state space by normalizing pixel values making it easier to process as well. Lastly, we manually combed through the files removing corrupted or improperly recorded data\n",
    "\n",
    "<histogram>\n",
    "\n",
    "<np.mean the states>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a205298f-5ec3-42a9-8112-b4d04459bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom imports\n",
    "from playback import get_state_action_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e364dc-8c03-45c3-90af-32511e2a0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_unnecessary_action(data):\n",
    "    action_space = data\n",
    "    \n",
    "    #This might not be necessary but im on a time crunch (Theres 100% a better way to do this)\n",
    "    action_map = {\n",
    "        64: 0,\n",
    "        65: 1,\n",
    "        66: 2,\n",
    "        67: 3,\n",
    "        128: 4,\n",
    "        129: 5,\n",
    "        130: 6,\n",
    "        131: 7\n",
    "    }\n",
    "    \n",
    "    # Map original action values to new values\n",
    "    action_space = np.array([action_map.get(action, 0) for action in action_space])\n",
    "    #print(action_space.size())\n",
    "    \n",
    "    return action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e86c9e4-388b-4587-93ca-0943e0fcd54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  imitation_mario_rec_carson_032124_145619.npz\n",
      "Adding  imitation_mario_rec_carson_032124_145652.npz\n",
      "Adding  imitation_mario_rec_carson_032124_143622.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate bar chart of action frequencies\n",
    "rec_state_history, rec_action_history = get_state_action_pairs(3)\n",
    "#load data\n",
    "rec_action_history = eliminate_unnecessary_action(rec_action_history)\n",
    "\n",
    "unique_vals, frequencies = np. unique(rec_action_history, return_counts = True)\n",
    "plt.bar(unique_vals, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1dc066d-3d80-4241-8d37-119f12ec3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_images(images):\n",
    "    average_image = np.mean(images, axis=0)\n",
    "    plt.imshow(average_image, cmap = 'gray')\n",
    "    plt. title('Average Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d62e5e8-dd96-4105-9d2c-0d06f7be7823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#np mean of states\n",
    "average_images(rec_state_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00380ee-e1f5-4933-b477-aa22beae37e9",
   "metadata": {},
   "source": [
    "# Classification Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c7809-0a65-4767-a59e-24a139de2bd8",
   "metadata": {},
   "source": [
    "## 1. KNN\n",
    "\n",
    "We used KNN as an example as to why our agent should not use classification methods using state-action pairs to solve the issue. One issue is KNN's susceptibility to noise. Since there are so many permutations to how a scene could be set depending on where the enemies are relative to the scene, it is hard for us to fully clean our data of noises as it is a large part of the game. \n",
    "\n",
    "Another issue for KNN is the curse of dimensionality. This dataset is composed of two numpy arrays: a 3D array that describes the environment and a 1D array that describes the action taken. In many cases in training, our players did drastically different actions at the same observation or the same action at a slightly different observation. Therefore, KNN has difficulties in finding similarities between records. This resulted in our KNN model taking vast amounts of time for training off of a singular isolated run and thus not finishing. We included the code as a large comment since it wil be unable to run in a realistic timeframe due to the sheer size of our data, even when drastically reducing the amount of data used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b321f5-20c2-4598-b877-8324f1296921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport gym\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\\nimport pickle\\nfrom datetime import datetime\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom tqdm import tqdm\\nfrom gym.wrappers import GrayScaleObservation\\nimport os\\nimport sklearn as sk\\nfrom sklearn.pipeline import Pipeline\\n\\n# Custom imports assuming these are correctly implemented\\nfrom playback import get_state_action_pairs\\n\\nclass knn:\\n    def __init__(self, model = None, n_n= 10):\\n        self.done = False\\n        self.name = \"KNN\"\\n\\n        #generates a pipeline that scales and decreases dimensions. \\n        if model is None:\\n            pline = Pipeline([(\\'scaler\\', sk.preprocessing.StandardScaler()), (\\'pca\\', sk.decomposition.PCA()), \\n                  (\\'knn\\', KNeighborsClassifier(n_neighbors= n_n))])\\n            self.model = pline\\n        else:\\n            self.model = model\\n\\n    def get_action(self, state):\\n        state = state.flatten().reshape(1, -1)\\n        return self.model.predict(state)\\n\\n    def train(self, state_history, action_history):\\n        self.model.fit(state_history, action_history)\\n        pickle.dump(self.model, open(\"knn.p\", \"wb\"))\\n        print(\"Training Complete.\")\\n\\n    def evaluate_and_tune(self, features, labels):\\n        parameters = {\\n             \\'n_neighbors\\': [None, 5, 10, 15]\\n        }\\n        cv = 5\\n        grid_search = GridSearchCV(self.model, parameters, cv=cv, scoring=\\'accuracy\\', return_train_score=True)\\n        grid_search.fit(features, labels)\\n\\n        print(\\'Best Parameters:\\', grid_search.best_params_)\\n        return grid_search\\n\\ndef plot_accuracy(grid_search):\\n    results = grid_search.cv_results_\\n    plt.figure(figsize=(10, 5))\\n    plt.title(\"Training vs Validation Accuracy\")\\n    plt.plot(results[\\'mean_train_score\\'], label=\\'Train Accuracy\\')\\n    plt.plot(results[\\'mean_test_score\\'], label=\\'Validation Accuracy\\')\\n    plt.xlabel(\\'Parameter Combination\\')\\n    plt.ylabel(\\'Accuracy\\')\\n    plt.legend()\\n    plt.show()\\n\\ndef run_agent(agent):\\n    env = GrayScaleObservation(gym.make(\"SuperMarioBros-v3\"))\\n    env.reset()\\n    done = False\\n    state_history = []\\n    action_history = []\\n\\n    with tqdm(total=100) as pbar:\\n        while not done:\\n            state, reward, done, _ = env.step(0)  # Example using a constant action\\n            action = agent.get_action(state)\\n            state_history.append(state)\\n            action_history.append(action)\\n            pbar.update(1)\\n\\n    env.close()\\n\\n\\n\\nif __name__ == \"__main__\":\\n    record_path = \"recordings\"\\n    \\n    if not os.path.isdir(record_path):\\n        print(f\"Error: {record_path} is not a valid directory.\")\\n    else:\\n        rec_state_history, rec_action_history = get_state_action_pairs(2)\\n\\n        if rec_state_history.ndim == 3:\\n            nsamples, height, width = rec_state_history.shape\\n            rec_state_history = rec_state_history.reshape((nsamples, height * width))\\n\\n        print(\"Reshaped state history shape:\", rec_state_history.shape)\\n\\n        train_states, test_states, train_actions, test_actions = train_test_split(\\n            rec_state_history, rec_action_history, test_size=0.2, random_state=42)\\n\\n        agent = knn()\\n        agent.train(train_states, train_actions)\\n\\n        grid_search = agent.evaluate_and_tune(train_states, train_actions)\\n        plot_accuracy(grid_search)\\n\\n        run_agent(agent)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom imports assuming these are correctly implemented\n",
    "from playback import get_state_action_pairs\n",
    "\n",
    "class knn:\n",
    "    def __init__(self, model = None, n_n= 10):\n",
    "        self.done = False\n",
    "        self.name = \"KNN\"\n",
    "\n",
    "        #generates a pipeline that scales and decreases dimensions. \n",
    "        if model is None:\n",
    "            pline = Pipeline([('scaler', sk.preprocessing.StandardScaler()), ('pca', sk.decomposition.PCA()), \n",
    "                  ('knn', KNeighborsClassifier(n_neighbors= n_n))])\n",
    "            self.model = pline\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = state.flatten().reshape(1, -1)\n",
    "        return self.model.predict(state)\n",
    "\n",
    "    def train(self, state_history, action_history):\n",
    "        self.model.fit(state_history, action_history)\n",
    "        pickle.dump(self.model, open(\"knn.p\", \"wb\"))\n",
    "        print(\"Training Complete.\")\n",
    "\n",
    "    def evaluate_and_tune(self, features, labels):\n",
    "        parameters = {\n",
    "             'n_neighbors': [None, 5, 10, 15]\n",
    "        }\n",
    "        cv = 5\n",
    "        grid_search = GridSearchCV(self.model, parameters, cv=cv, scoring='accuracy', return_train_score=True)\n",
    "        grid_search.fit(features, labels)\n",
    "\n",
    "        print('Best Parameters:', grid_search.best_params_)\n",
    "        return grid_search\n",
    "\n",
    "def plot_accuracy(grid_search):\n",
    "    results = grid_search.cv_results_\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Training vs Validation Accuracy\")\n",
    "    plt.plot(results['mean_train_score'], label='Train Accuracy')\n",
    "    plt.plot(results['mean_test_score'], label='Validation Accuracy')\n",
    "    plt.xlabel('Parameter Combination')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def run_agent(agent):\n",
    "    env = GrayScaleObservation(gym.make(\"SuperMarioBros-v3\"))\n",
    "    env.reset()\n",
    "    done = False\n",
    "    state_history = []\n",
    "    action_history = []\n",
    "\n",
    "    with tqdm(total=100) as pbar:\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(0)  # Example using a constant action\n",
    "            action = agent.get_action(state)\n",
    "            state_history.append(state)\n",
    "            action_history.append(action)\n",
    "            pbar.update(1)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    record_path = \"recordings\"\n",
    "    \n",
    "    if not os.path.isdir(record_path):\n",
    "        print(f\"Error: {record_path} is not a valid directory.\")\n",
    "    else:\n",
    "        rec_state_history, rec_action_history = get_state_action_pairs(2)\n",
    "\n",
    "        if rec_state_history.ndim == 3:\n",
    "            nsamples, height, width = rec_state_history.shape\n",
    "            rec_state_history = rec_state_history.reshape((nsamples, height * width))\n",
    "\n",
    "        print(\"Reshaped state history shape:\", rec_state_history.shape)\n",
    "\n",
    "        train_states, test_states, train_actions, test_actions = train_test_split(\n",
    "            rec_state_history, rec_action_history, test_size=0.2, random_state=42)\n",
    "\n",
    "        agent = knn()\n",
    "        agent.train(train_states, train_actions)\n",
    "\n",
    "        grid_search = agent.evaluate_and_tune(train_states, train_actions)\n",
    "        plot_accuracy(grid_search)\n",
    "\n",
    "        run_agent(agent)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fbec4-e486-4699-8fec-79df63948353",
   "metadata": {},
   "source": [
    "# 2. Decision Trees\n",
    "We also used a decision tree to further demonstrate how classification using state-action pairs was inappropriate for our problem. Our data is filled with many occurrences of the same observation but slightly different actions in reaction to the same environment. \n",
    "In one run, the same person could jump at a frame earlier and thus not jump at the consequent frame or the same person could jump\n",
    "at the consequent frame and not do anything in the frame prior. This makes it difficult for the agent to draw similarities\n",
    "between runs, making it hard for the tree to fit an action to a specific state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b910ab2-1e6f-4c90-87d1-75cc847911e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for decision trees\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "import os\n",
    "from sklearn import tree\n",
    "# Custom imports\n",
    "from playback import get_state_action_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3193e4-9348-4c2c-9a4b-c1dec751aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Class\n",
    "class DecisionTree:\n",
    "    def __init__(self, model = None, max_d = 10, dummy = False):\n",
    "        self.done = False\n",
    "        self.name = \"decision_tree\"\n",
    "        if model is None:\n",
    "            self.model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_d)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = state.flatten().reshape(1, -1)\n",
    "        return self.model.predict(state)\n",
    "\n",
    "    def train(self, state_history, action_history):\n",
    "        self.model.fit(state_history, action_history)\n",
    "        pickle.dump(self.model, open(\"decision_tree_model.p\", \"wb\"))\n",
    "        print(\"Training Complete.\")\n",
    "\n",
    "    def evaluate_and_tune(self, features, labels):\n",
    "        parameters = {\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': [None, 10, 20, 30]\n",
    "        }\n",
    "        cv = 5\n",
    "        grid_search = GridSearchCV(self.model, parameters, cv=cv, scoring='accuracy', return_train_score=True)\n",
    "        grid_search.fit(features, labels)\n",
    "\n",
    "        print('Best Parameters:', grid_search.best_params_)\n",
    "        return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574bcedd-7a81-462a-8454-5760530a9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(agent):\n",
    "    env = GrayScaleObservation(gym.make(\"SuperMarioBros-v3\"))\n",
    "    env.reset()\n",
    "    done = False\n",
    "    state_history = []\n",
    "    action_history = []\n",
    "\n",
    "    with tqdm(total=100) as pbar:\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(0)  # Example using a constant action\n",
    "            action = agent.get_action(state)\n",
    "            state_history.append(state)\n",
    "            action_history.append(action)\n",
    "            pbar.update(1)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44995d-c13a-4604-bfee-99492f526c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  imitation_mario_rec_carson_032124_145619.npz\n",
      "Adding  imitation_mario_rec_carson_032124_145652.npz\n",
      "Reshaped state history shape: (6707, 61440)\n",
      "Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathew/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "record_path = \"recordings\"\n",
    "\n",
    "if not os.path.isdir(record_path):\n",
    "    print(f\"Error: {record_path} is not a valid directory.\")\n",
    "else:\n",
    "    rec_state_history, rec_action_history = get_state_action_pairs(2)\n",
    "\n",
    "    if rec_state_history.ndim == 3:\n",
    "        nsamples, height, width = rec_state_history.shape\n",
    "        rec_state_history = rec_state_history.reshape((nsamples, height * width))\n",
    "\n",
    "    print(\"Reshaped state history shape:\", rec_state_history.shape)\n",
    "\n",
    "    train_states, test_states, train_actions, test_actions = train_test_split(\n",
    "        rec_state_history, rec_action_history, test_size=0.2, random_state=42)\n",
    "\n",
    "    agent = DecisionTree()\n",
    "    agent.train(train_states, train_actions)\n",
    "\n",
    "    grid_search = agent.evaluate_and_tune(train_states, train_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10e314-1ceb-4b96-a64a-dd85874d8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15e28e-6f07-4b0b-b991-c345eb161ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "sets = ['set 1', 'set 2', 'set 3', 'set 4', 'set 5' , 'set 6', 'set 7', 'set 8', 'set 9', 'set 10', 'set 11', 'set 12']\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.bar(sets, results['mean_train_score'], width= 0.5)\n",
    "plt.xlabel('Parameter Combination')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a662e-856f-45ad-9637-03086ae646af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.bar(sets, results['mean_test_score'], width= 0.5)\n",
    "plt.xlabel('Parameter Combination')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66e696-0334-4c63-94db-5cac94b343cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('combinations:      \\nset 1: gini + none      \\nset 2: gini + 10      \\nset 3: gini + 20 \\nset 4: gini+ 30 \\nset 5: entropy + none \\nset 6: entropy + 10 \\nset 7: entropy + 20 \\nset 8: entropy + 30 \\nset 9: log loss + none \\nset 10: log loss + 10 \\nset 11: log loss + 20 \\nset 12: log loss + 30 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bafbb-8437-4b11-83ce-ab35f25aa9fa",
   "metadata": {},
   "source": [
    "# 3. ADABoosting\n",
    "We used ADABoosting as an example as to why our agent should not use classification methods using state-action pairs to play super mario. Though the accuracy of the boosting model is generally higher than techniques alone, in our case, since we are using ensembling in a supervised learning way based on the decision tree stump model, the ensemble booster model accuracy is ____. Since the goal of our classification is to classify in a way that allows the model to beat the super mario game, the application of ensembling wouldn't be the best as it would base the action it takes strictly on the states ran through by a mario play-through done by the user, which could be susceptible to faulty playthroughs. If we were to apply an RL agent on the other hand which creates policies on the premise of maximizing rewards as our model for ADABoosting, it would likely be a good approach as the accuracy would be increased substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b53c5181-42c4-4498-aeb1-d0d7f1abb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from nes_py.app.play_human import play_human\n",
    "from gym.wrappers.gray_scale_observation import GrayScaleObservation\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import *\n",
    "import pickle\n",
    "from playback import get_state_action_pairs\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d52f55fb-1912-4e83-85e0-e8027aaf9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABoost\n",
    "class boosting_agent:\n",
    "    def __init__(self, model = None, n_estimators = 50):\n",
    "        self.done = False\n",
    "        self.name = \"boosting_agent\"\n",
    "        if model is None:\n",
    "            self.model = AdaBoostClassifier(n_estimators = n_estimators)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = state.flatten().reshape(1, -1)\n",
    "        return self.model.predict(state)\n",
    "\n",
    "    def train(self, state_history, action_history):\n",
    "        self.model.fit(state_history, action_history)\n",
    "        pickle.dump(self.model, open(\"booster_model.p\", \"wb\"))\n",
    "        print(\"Training Complete.\")\n",
    "\n",
    "    def evaluate_and_tune(self, features, labels):\n",
    "        parameters = {\n",
    "            'n_estimators': [40, 50, 60],\n",
    "            'learning_rate': [0.8, 1.0, 1.2]\n",
    "        }\n",
    "        cv = 5\n",
    "        grid_search = GridSearchCV(self.model, parameters, cv=cv, scoring='accuracy', return_train_score=True)\n",
    "        grid_search.fit(features, labels)\n",
    "\n",
    "        print('Best Parameters:', grid_search.best_params_)\n",
    "        return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "601b3835-413a-41c4-b34f-0a498418a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(agent):\n",
    "    env = GrayScaleObservation(gym.make(\"SuperMarioBros-v3\"))\n",
    "    env.reset()\n",
    "    done = False\n",
    "    state_history = []\n",
    "    action_history = []\n",
    "\n",
    "    with tqdm(total=100) as pbar:\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(0)  # Example using a constant action\n",
    "            action = agent.get_action(state)\n",
    "            state_history.append(state)\n",
    "            action_history.append(action)\n",
    "            pbar.update(1)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538de86f-fa07-4f18-8f9a-9b40bec36fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  imitation_mario_rec_carson_032124_145619.npz\n",
      "Adding  imitation_mario_rec_carson_032124_145652.npz\n",
      "Reshaped state history shape: (6707, 61440)\n"
     ]
    }
   ],
   "source": [
    "record_path = \"recordings\"\n",
    "\n",
    "if not os.path.isdir(record_path):\n",
    "    print(f\"Error: {record_path} is not a valid directory.\")\n",
    "else:\n",
    "    rec_state_history, rec_action_history = get_state_action_pairs(2)\n",
    "\n",
    "    if rec_state_history.ndim == 3:\n",
    "        nsamples, height, width = rec_state_history.shape\n",
    "        rec_state_history = rec_state_history.reshape((nsamples, height * width))\n",
    "\n",
    "    print(\"Reshaped state history shape:\", rec_state_history.shape)\n",
    "\n",
    "    train_states, test_states, train_actions, test_actions = train_test_split(\n",
    "        rec_state_history, rec_action_history, test_size=0.2, random_state=42)\n",
    "\n",
    "    agent = boosting_agent()\n",
    "    agent.train(train_states, train_actions)\n",
    "\n",
    "    grid_search = agent.evaluate_and_tune(train_states, train_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e60cc4-1365-4eea-b0e5-daa9f9f74eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e14e1-e0c0-4398-a378-2946fa2533c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "sets = ['set 1', 'set 2', 'set 3', 'set 4', 'set 5' , 'set 6', 'set 7', 'set 8', 'set 9']\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.bar(sets, results['mean_train_score'], width= 0.5)\n",
    "plt.xlabel('Parameter Combination')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce108d-876b-4300-a0f4-574a724067a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.bar(sets, results['mean_test_score'], width= 0.5)\n",
    "plt.xlabel('Parameter Combination')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1055106-949a-4cab-a66e-5cfc597e1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('combinations (n estimators, learning rate) :\\nset 1: (40, 0.8) \\nset 2: (40, 1.0) \\nset 3: (40, 1.2) \\nset 4: (50, 0.8) \\nset 5 (50, 1.0) \\nset 6 (50, 1.2) \\nset 7 (60, 0.8) \\nset 8(60, 1.0) \\nset 9 (60, 1.2)\n",
    "\n",
    "      'n_estimators': [40, 50, 60],\n",
    "            'learning_rate': [0.8, 1.0: 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd9ab3",
   "metadata": {},
   "source": [
    "# 4. CNN\n",
    "\n",
    "Process: Our process involved splitting the dataset into training and validation sets using a 80-20 ratio. We tested every combination of kernel size and activation function for 4 epochs. Once we decided not to vary our batch size we kept it constant at 32. We then recorded the training histories which included the training and validation accuracies for each combination of hyperparameters.\n",
    "\n",
    "Conclusion: Based on hyperparameter tuning we found that the combination of a kernel size with (3,3) and the tanh activation function seemed to be the most effective as evidenced by the training and validation accuracy.\n",
    "\n",
    "Further steps: In order to further tune our hyperparameters to make more accurate predictions we could vary the number of our convolutional layers. Since increasing the number of convolutional layers may allow our model to distinguish between more complex representations, we may be able to improve our performance. We could also test different learning rates to optimize convergence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b382e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "import gym\n",
    "import nes_py\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from nes_py.app.play_human import play_human\n",
    "from gym.wrappers.gray_scale_observation import GrayScaleObservation\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pickle\n",
    "from playback import get_state_action_pairs \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79446eca",
   "metadata": {},
   "source": [
    "The below code converts our game space from rgb to grayscale. Eliminate unecessary action remaps our actionspace from 0->7 as this is what our action input data is looking for. Each number responds to a specific action such as 128 occurs when the user click d and it causes Mario to move forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def eliminate_unnecessary_action(data):\n",
    "    action_space = data\n",
    "    action_map = {\n",
    "        64: 0,\n",
    "        65: 1,\n",
    "        66: 2,\n",
    "        67: 3,\n",
    "        128: 4,\n",
    "        129: 5,\n",
    "        130: 6,\n",
    "        131: 7\n",
    "    }\n",
    "    \n",
    "    action_space = np.array([action_map.get(action, 0) for action in action_space])\n",
    "    return action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0275a2",
   "metadata": {},
   "source": [
    "The code below defines a specific CNN architecture. It is using TensorFlow's keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model with specific layers, some values given from CNN tutorial with tensorflow\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6820097",
   "metadata": {},
   "source": [
    "Kernel Sizes: We tested three different kernel sizes ((3,3),(5,5),(7,7)). As a smaller kernel sizes focus on smaller regions of our input image, we expected the larger kernel sizes to be more effective as they would capture a wider range of information from our input image.\n",
    "\n",
    "Activation Functions: We tested three different activation functions (Rectified Linear Unit, Hyperbolic Tangent, and Sigmoid).\n",
    "As relu (Rectified Linear Unit), is known for its effectiveness with regards to deep learning models, we expected it to perform the best.\n",
    "\n",
    "Note: Tried batch sizes but didn't feel it had a significant enough change in our accuracy. Now we set our batch size to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(state_history, action_history):\n",
    "    kernel_sizes = [(3, 3), (5, 5),(7,7)]\n",
    "    activation_functions = ['relu','tanh','sigmoid']\n",
    "    #batch_sizes = [32, 64, 128]\n",
    "\n",
    "    training_histories = []\n",
    "    accuracies = []\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "        for activation_function in activation_functions:\n",
    "            print(f\"training with kernel size: {kernel_size} and activation function: {activation_function}\")\n",
    "            train_a, test_a, train_b, test_b = train_test_split(state_history, action_history, test_size=0.2, random_state=42)\n",
    "            train_a = np.expand_dims(train_a, axis=-1)\n",
    "            test_a = np.expand_dims(test_a, axis=-1)\n",
    "            \n",
    "            train_a = train_a / 255.0\n",
    "            test_a = test_a / 255.0\n",
    "\n",
    "            model = create_cnn(input_shape=(state_history.shape[1], state_history.shape[2], 1), num_classes=np.max(action_history) + 1)\n",
    "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            history = model.fit(train_a, train_b, epochs=4, batch_size=32, validation_data=(test_a, test_b))\n",
    "\n",
    "            training_histories.append(history)\n",
    "            accuracies.append(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16223893",
   "metadata": {},
   "source": [
    "The code below graphs both the training accuracy and the validation accuracy over a specified amount of epochs. The graph line colors correspond to the specific combination of kernel sizes and and activation functions. The same combination color is used for the training accuracy and the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fe9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.figure(figsize=(10, 12))\n",
    "    colors = plt.cm.tab10.colors[:len(kernel_sizes) * len(activation_functions)]\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i, kernel_size in enumerate(kernel_sizes):\n",
    "        for j, activation_function in enumerate(activation_functions):\n",
    "            plt.plot(range(1, 5), training_histories[i*len(activation_functions)+j].history['accuracy'], label=f'kernel size:{kernel_size}, activation:{activation_function}')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),ncol=3,fontsize='small')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i, kernel_size in enumerate(kernel_sizes):\n",
    "        for j, activation_function in enumerate(activation_functions):\n",
    "            color = colors[i*len(activation_functions)+j\n",
    "            plt.plot(range(1, 5), training_histories[i*len(activation_functions)+j].history['val_accuracy'], label=f'kernel size: {kernel_size}, activation:{activation_function}', color=color)\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('validation accuracy')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, fontsize='small')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Validation Accuracies:\")\n",
    "    for i, kernel_size in enumerate(kernel_sizes):\n",
    "        for j, activation_function in enumerate(activation_functions):\n",
    "            print(f'kernel size:{kernel_size}, activation:{activation_function}: {accuracies[i*len(activation_functions)+j]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c49bf",
   "metadata": {},
   "source": [
    "Define the CNN Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAgent:\n",
    "    def __init__(self, model=None, state_history=None, action_history=None):\n",
    "        self.done = False\n",
    "        self.name = \"cnn_agent\"\n",
    "        if model is None:\n",
    "            num_classes = np.max(action_history) + 1\n",
    "            self.model = create_cnn(input_shape=(state_history.shape[1], state_history.shape[2], 1), num_classes=num_classes)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        state = np.expand_dims(state, axis=-1)\n",
    "        return np.argmax(self.model.predict(state))\n",
    "        \n",
    "    def train(self, state_history, action_history):\n",
    "\n",
    "        print(\"Training...\")\n",
    "        train_a, test_a, train_b, test_b = train_test_split(state_history, action_history, test_size=0.2, random_state=42)\n",
    "        train_a = np.expand_dims(train_a, axis=-1)\n",
    "        test_a = np.expand_dims(test_a, axis=-1)\n",
    "        train_a = train_a / 255.0\n",
    "        test_a = test_a / 255.0\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = self.model.fit(train_a, train_b, epochs=1, validation_data=(test_a, test_b))\n",
    "        self.model.save(\"models/cnn_model.h5\")\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "        #Graph validation and training accuracy as epochs increase\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(agent):\n",
    "\n",
    "    env = GrayScaleObservation(gym_super_mario_bros.make(\"SuperMarioBros-v3\"))\n",
    "    env.reset()\n",
    "\n",
    "    action_history = []\n",
    "    state_history = []\n",
    "    reward_history = []\n",
    "\n",
    "    action = [0]\n",
    "    done = False\n",
    "    while not done:\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        action_history.append(action)\n",
    "        state_history.append(rgb2gray(state))\n",
    "        reward_history.append(reward)\n",
    "        action = agent.get_action(state)\n",
    "        if done:\n",
    "            print(\"Done\")\n",
    "            break\n",
    "        if agent.done:\n",
    "            print(\"Agent done\")\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "    day_time = datetime.today().strftime(\"%m%d%y_%H%M%S\")\n",
    "    np.savez(f\".\\\\agent_recordings\\\\{agent.name}_{day_time}\", np.array(state_history), np.array(action_history), np.array(reward_history))\n",
    "    print(\"Recording saved\")\n",
    "    env.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Windows closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rec_state_history, rec_action_history = get_state_action_pairs(2)\n",
    "rec_action_history = eliminate_unnecessary_action(rec_action_history)\n",
    "agent = CNNAgent(model=None, state_history=rec_state_history, action_history=rec_action_history)\n",
    "hyperparameter_tuning(rec_state_history, rec_action_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29746f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56728210-9c95-4324-b778-24f15d242506",
   "metadata": {},
   "source": [
    "# 4. Proximal Policy Optimization using Stable Baselines 3\n",
    "After finding that most classification approaches failed to yield useful results, we decided to consult the literature for a more appropriate approach. Promimal Policy Optimization (https://arxiv.org/pdf/1707.06347.pdf) is a reinforcement learning approach developed by OpenAI in 2017. Since then it has become a standard approach for reinforcement learning tasks. After doing some research online, we were able to find a utility wrapper for the SuperMarioBros gym environment. This wrapper accesses the RAM of the NES simulator directly, exposing the location of Mario and the scene features directly. This makes it easier for PPO to learn a performant policy more quickly as it doesn't need to learn the mapping from the image space to semanticly meaningful features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78297ee1-9587-44e9-a065-9e822348eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All necessary imports\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym \n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, RIGHT_ONLY \n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from gym_utils import SMBRamWrapper\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539a40c-00d9-49ec-8c28-8dc747cec589",
   "metadata": {},
   "source": [
    "### Defining Callback and Helper Functions\n",
    "The logging callback class is used to populate the score/time_step lists for later display.  \n",
    "The linear schedule is derived from the stablebaselines documentation, and is considered a standard approach for PPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bfb10e-357f-412c-b8af-c21e3f39fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, env_wrap, starting_steps=0, verbose=1):\n",
    "        super(EvaluationCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.starting_steps = starting_steps\n",
    "        self.evaluations = []\n",
    "\n",
    "    def _init_callback(self):\n",
    "        self.env_wrap = self.model.get_env()\n",
    "        print(\"Initialized Callback\")\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            eval = evaluate_policy(self.model, self.env_wrap, n_eval_episodes=1, deterministic=True, render=False, return_episode_rewards=False)\n",
    "            self.evaluations.append(eval[0])\n",
    "        return True\n",
    "    \n",
    "# Linear learning rate schedule\n",
    "# https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#learning-rate-schedule\n",
    "from typing import Callable\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68608b1-0435-47fe-85ca-9be64d75e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v3')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "x0 = 0\n",
    "x1 = 16\n",
    "y0 = 0\n",
    "y1 = 13\n",
    "n_stack = 4\n",
    "n_skip = 4\n",
    "env_wrap = SMBRamWrapper(env, [x0, x1, y0, y1], n_stack=n_stack, n_skip=n_skip)\n",
    "env_wrap = Monitor(env_wrap)\n",
    "env_wrap = DummyVecEnv([lambda: env_wrap])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ccad8c-13c4-4b5a-b9c3-f17e42576588",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_time = datetime.today().strftime(\"%m%d%y_%H%M%S\")\n",
    "MODEL_DIR = './models/PPO_' + day_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444688c3-0c6b-4aa7-82a6-2287674185c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bs:  16  n_e:  8  gamma:  0.8\n",
      "Evaluation performance:  (232.0, 0.0)\n",
      "Training bs:  16  n_e:  8  gamma:  0.9\n",
      "Evaluation performance:  (232.0, 0.0)\n",
      "Training bs:  16  n_e:  8  gamma:  0.99\n",
      "Evaluation performance:  (232.0, 0.0)\n",
      "Training bs:  16  n_e:  10  gamma:  0.8\n",
      "Evaluation performance:  (252.0, 0.0)\n",
      "Training bs:  16  n_e:  10  gamma:  0.9\n",
      "Evaluation performance:  (232.0, 0.0)\n",
      "Training bs:  16  n_e:  10  gamma:  0.99\n",
      "Evaluation performance:  (-415.0, 0.0)\n",
      "Training bs:  16  n_e:  12  gamma:  0.8\n",
      "Evaluation performance:  (232.0, 0.0)\n",
      "Training bs:  16  n_e:  12  gamma:  0.9\n",
      "Evaluation performance:  (-415.0, 0.0)\n",
      "Training bs:  16  n_e:  12  gamma:  0.99\n",
      "Evaluation performance:  (252.0, 0.0)\n",
      "Training bs:  32  n_e:  8  gamma:  0.8\n",
      "Evaluation performance:  (-455.0, 0.0)\n",
      "Training bs:  32  n_e:  8  gamma:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune on\n",
    "batch_sizes = [16,32,64]\n",
    "n_epochs = [8,10,12]\n",
    "gammas = [0.8,0.9,0.99]\n",
    "\n",
    "models = []\n",
    "evals = []\n",
    "for batch_size in batch_sizes:\n",
    "    for n_epoch in n_epochs:\n",
    "        for gamma in gammas:\n",
    "            print(\"Training bs: \", batch_size, \" n_e: \", n_epoch, \" gamma: \", gamma)\n",
    "            model = PPO('MlpPolicy', env_wrap, verbose=0, learning_rate=linear_schedule(3e-4), batch_size=batch_size,n_epochs=n_epoch,gamma=gamma) \n",
    "            model.learn(total_timesteps=1e2)\n",
    "            eval = evaluate_policy(model, env_wrap, n_eval_episodes=1, deterministic=True, render=False, return_episode_rewards=False)\n",
    "            models.append(model)\n",
    "            evals.append(eval)\n",
    "            print(\"Evaluation performance: \", eval)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74708140-9489-48ce-9e4c-0e85df03d267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ed1e9-b06b-4d5c-a8d0-8a0e2676239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training all of the models\n",
    "# t_start = time.time()\n",
    "# model.learn(total_timesteps=10e3, callback=callback,progress_bar=True)\n",
    "# t_elapsed = time.time() - t_start\n",
    "# print('Wall time: {} s'.format(round(t_elapsed, 2)))\n",
    "# # Save model\n",
    "# model_path = os.path.join(MODEL_DIR)\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0337e-915b-4bfd-bf5a-66e8001cc6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "evaluate_policy(model, env_wrap, n_eval_episodes=1, deterministic=True, render=False, return_episode_rewards=False)\n",
    "plt.figure()\n",
    "plt.plot(callback.evaluations)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca74b7-9c9f-4bb2-9884-3cd11479182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 1\n",
    "\n",
    "for episode in range(1, episode+1):\n",
    "    states = env_wrap.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env_wrap.render()\n",
    "        action, _ = model.predict(states, deterministic=True)\n",
    "        states, reward, done, info = env_wrap.step(action)\n",
    "        score += reward\n",
    "        time.sleep(0.01)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cdb7f-b6e8-409a-9763-9219199bb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee92a4-1425-466d-ae9f-70090c3c8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback.evaluations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
